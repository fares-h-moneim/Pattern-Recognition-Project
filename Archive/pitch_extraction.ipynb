{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1455d3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from sklearn.model_selection    import train_test_split\n",
    "from sklearn.preprocessing      import StandardScaler\n",
    "from sklearn.pipeline           import Pipeline\n",
    "from sklearn.ensemble           import RandomForestClassifier\n",
    "from sklearn.neighbors          import KNeighborsClassifier\n",
    "from sklearn.svm                import SVC\n",
    "from sklearn.semi_supervised    import LabelPropagation\n",
    "from sklearn.metrics            import classification_report, confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE         = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DATA_CSV       = './Data/data_labeled_filtered.csv'\n",
    "AUDIO_ROOT     = './Data/Audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d572fb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not check for FFmpeg backend (might be an older torchaudio version). Assuming it might work.\n",
      "Loading data from ./Data/data_labeled_filtered.csv...\n",
      "Using device: cuda\n",
      "Starting pitch extraction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting pitch:   0%|          | 5/172158 [00:02<22:14:10,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detect_pitch_frequency failed for common_voice_en_19687174.mp3: RuntimeError: maximum size for tensor at dimension 1 is 1006 but size is 1024. Trying fallback.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting pitch:   0%|          | 6/172158 [00:02<21:32:57,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detect_pitch_frequency failed for common_voice_en_18421093.mp3: RuntimeError: maximum size for tensor at dimension 1 is 948 but size is 1024. Trying fallback.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting pitch:   0%|          | 7/172158 [00:03<20:58:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detect_pitch_frequency failed for common_voice_en_18421094.mp3: RuntimeError: maximum size for tensor at dimension 1 is 874 but size is 1024. Trying fallback.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting pitch:   0%|          | 8/172158 [00:03<20:52:19,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detect_pitch_frequency failed for common_voice_en_18421095.mp3: RuntimeError: maximum size for tensor at dimension 1 is 963 but size is 1024. Trying fallback.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting pitch:   0%|          | 9/172158 [00:04<20:37:15,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detect_pitch_frequency failed for common_voice_en_18421096.mp3: RuntimeError: maximum size for tensor at dimension 1 is 946 but size is 1024. Trying fallback.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting pitch:   0%|          | 15/172158 [00:06<19:10:32,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detect_pitch_frequency failed for common_voice_en_18841725.mp3: RuntimeError: maximum size for tensor at dimension 1 is 987 but size is 1024. Trying fallback.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting pitch:   0%|          | 16/172158 [00:06<19:11:34,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detect_pitch_frequency failed for common_voice_en_19093168.mp3: RuntimeError: maximum size for tensor at dimension 1 is 1013 but size is 1024. Trying fallback.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting pitch:   0%|          | 17/172158 [00:07<19:13:57,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detect_pitch_frequency failed for common_voice_en_19093169.mp3: RuntimeError: maximum size for tensor at dimension 1 is 994 but size is 1024. Trying fallback.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting pitch:   0%|          | 21/172158 [00:09<21:01:11,  2.27it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 153\u001b[0m\n\u001b[0;32m    149\u001b[0m audio_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(AUDIO_ROOT, relative_path)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(audio_file):\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# extract_pitch handles internal errors and returns None on failure\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     pitch_value \u001b[38;5;241m=\u001b[39m \u001b[43mextract_pitch\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# Use .loc for potentially faster assignment, especially on large dataframes\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpitch_mean\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pitch_value\n",
      "Cell \u001b[1;32mIn[9], line 89\u001b[0m, in \u001b[0;36mextract_pitch\u001b[1;34m(audio_path)\u001b[0m\n\u001b[0;32m     85\u001b[0m      \u001b[38;5;66;03m# Or adjust win_length = waveform.shape[-1] if you want to process very short files\u001b[39;00m\n\u001b[0;32m     86\u001b[0m      \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m pitch \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_pitch_frequency\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Corresponds to hop_length = int(sample_rate * frame_time)\u001b[39;49;00m\n\u001b[0;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Using the adjusted window length\u001b[39;49;00m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreq_low\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreq_high\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500.0\u001b[39;49m\n\u001b[0;32m     96\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     98\u001b[0m pitch \u001b[38;5;241m=\u001b[39m pitch[pitch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pitch\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchaudio\\functional\\functional.py:1146\u001b[0m, in \u001b[0;36mdetect_pitch_frequency\u001b[1;34m(waveform, sample_rate, frame_time, win_length, freq_low, freq_high)\u001b[0m\n\u001b[0;32m   1143\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(waveform\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m   1144\u001b[0m waveform \u001b[38;5;241m=\u001b[39m waveform\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m-> 1146\u001b[0m nccf \u001b[38;5;241m=\u001b[39m \u001b[43m_compute_nccf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_low\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1147\u001b[0m indices \u001b[38;5;241m=\u001b[39m _find_max_per_frame(nccf, sample_rate, freq_high)\n\u001b[0;32m   1148\u001b[0m indices \u001b[38;5;241m=\u001b[39m _median_smoothing(indices, win_length)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchaudio\\functional\\functional.py:1048\u001b[0m, in \u001b[0;36m_compute_nccf\u001b[1;34m(waveform, sample_rate, frame_time, freq_low)\u001b[0m\n\u001b[0;32m   1042\u001b[0m     s1 \u001b[38;5;241m=\u001b[39m waveform[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m-\u001b[39mlag]\u001b[38;5;241m.\u001b[39munfold(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, frame_size, frame_size)[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :num_of_frames, :]\n\u001b[0;32m   1043\u001b[0m     s2 \u001b[38;5;241m=\u001b[39m waveform[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, lag:]\u001b[38;5;241m.\u001b[39munfold(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, frame_size, frame_size)[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :num_of_frames, :]\n\u001b[0;32m   1045\u001b[0m     output_frames \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1046\u001b[0m         (s1 \u001b[38;5;241m*\u001b[39m s2)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   1047\u001b[0m         \u001b[38;5;241m/\u001b[39m (EPSILON \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvector_norm(s1, \u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m-> 1048\u001b[0m         \u001b[38;5;241m/\u001b[39m (EPSILON \u001b[38;5;241m+\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mord\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m   1049\u001b[0m     )\n\u001b[0;32m   1051\u001b[0m     output_lag\u001b[38;5;241m.\u001b[39mappend(output_frames\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   1053\u001b[0m nccf \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(output_lag, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio.functional import detect_pitch_frequency, spectrogram\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "# --- Configuration ---\n",
    "# Constants\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATA_CSV = './Data/data_labeled_filtered.csv' # Path to your input CSV\n",
    "AUDIO_ROOT = './Data/Audio' # Root directory containing audio subfolders/files\n",
    "OUTPUT_CSV = './Data/data_labeled_filtered_with_pitch.csv' # Path to save the output CSV\n",
    "\n",
    "# --- FFmpeg Backend Check (Optional but Recommended) ---\n",
    "try:\n",
    "    # Check if ffmpeg backend is available\n",
    "    torchaudio.utils.ffmpeg_available()\n",
    "    # You might want to explicitly set the backend, though often not necessary if ffmpeg is in PATH\n",
    "    # torchaudio.set_audio_backend(\"ffmpeg\")\n",
    "    print(\"FFmpeg backend found.\")\n",
    "except RuntimeError:\n",
    "    warnings.warn(\n",
    "        \"FFmpeg backend not available. MP3 loading might fail. \"\n",
    "        \"Please install FFmpeg and ensure it's in your system's PATH.\"\n",
    "    )\n",
    "except AttributeError:\n",
    "     # Older torchaudio versions might not have ffmpeg_available()\n",
    "     print(\"Could not check for FFmpeg backend (might be an older torchaudio version). Assuming it might work.\")\n",
    "\n",
    "\n",
    "# --- Load Data ---\n",
    "print(f\"Loading data from {DATA_CSV}...\")\n",
    "try:\n",
    "    df = pd.read_csv(DATA_CSV)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Input CSV file not found at {DATA_CSV}\")\n",
    "    exit()\n",
    "\n",
    "# Initialize the new column, overwriting if it exists\n",
    "df['pitch_mean'] = None\n",
    "# Ensure the pitch column is float type to handle NaN/None properly\n",
    "df['pitch_mean'] = df['pitch_mean'].astype(float)\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- Pitch Extraction Function ---\n",
    "def extract_pitch(audio_path):\n",
    "    \"\"\"\n",
    "    Extracts the mean pitch (F0) from an audio file.\n",
    "    Returns the mean pitch frequency (float) or None if pitch cannot be detected or an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        waveform, sample_rate = torchaudio.load(audio_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading audio file {os.path.basename(audio_path)}: {e}\")\n",
    "        return None\n",
    "\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "\n",
    "    waveform = waveform.to(DEVICE)\n",
    "\n",
    "    # --- Method 1: detect_pitch_frequency (Preferred) ---\n",
    "    try:\n",
    "        # --- ADJUSTMENT ---\n",
    "        # Instead of strictly 30ms, let's try a fixed window size like 1024 samples.\n",
    "        # This is common in FFT-based methods and might avoid internal size conflicts.\n",
    "        # 1024 samples at 48kHz is ~21.3ms, which is still reasonable for pitch.\n",
    "        # You could also try 2048 (~42.6ms) if 1024 is too short for low pitches.\n",
    "        # Let's start with 1024.\n",
    "        win_length = 1024\n",
    "\n",
    "        # Keep the hop time at 10ms\n",
    "        frame_time = 0.01\n",
    "        # The hop_length in samples would be int(sample_rate * frame_time)\n",
    "        # e.g., 480 samples at 48kHz\n",
    "\n",
    "        # Ensure win_length is not smaller than what the function requires internally\n",
    "        # (Usually not an issue unless win_length is made very small)\n",
    "        # And ensure win_length <= waveform length\n",
    "        if win_length > waveform.shape[-1]:\n",
    "             print(f\"Warning: win_length ({win_length}) > waveform length ({waveform.shape[-1]}) for {os.path.basename(audio_path)}. Skipping pitch detection.\")\n",
    "             # Or adjust win_length = waveform.shape[-1] if you want to process very short files\n",
    "             return None\n",
    "\n",
    "\n",
    "        pitch = detect_pitch_frequency(\n",
    "            waveform,\n",
    "            sample_rate=sample_rate,\n",
    "            frame_time=frame_time,  # Corresponds to hop_length = int(sample_rate * frame_time)\n",
    "            win_length=win_length,  # Using the adjusted window length\n",
    "            freq_low=50.0,\n",
    "            freq_high=500.0\n",
    "        ).squeeze()\n",
    "\n",
    "        pitch = pitch[pitch > 0]\n",
    "\n",
    "        if pitch.numel() > 0:\n",
    "            return pitch.mean().item()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        # Print the specific error type and message for better debugging\n",
    "        print(f\"detect_pitch_frequency failed for {os.path.basename(audio_path)}: {type(e).__name__}: {e}. Trying fallback.\")\n",
    "\n",
    "        # --- Method 2: Spectrogram-based Fallback (Less Accurate) ---\n",
    "        # (Fallback code remains the same as before)\n",
    "        try:\n",
    "            n_fft = 1024\n",
    "            spec_win_length = 400 # Can keep this independent or link to pitch win_length\n",
    "            spec_hop_length = 100\n",
    "            window = torch.hann_window(spec_win_length).to(DEVICE)\n",
    "\n",
    "            spec = spectrogram(\n",
    "                waveform=waveform, pad=0, window=window, n_fft=n_fft,\n",
    "                hop_length=spec_hop_length, win_length=spec_win_length,\n",
    "                power=1, normalized=False,\n",
    "            ).squeeze(0)\n",
    "\n",
    "            freqs = torch.fft.rfftfreq(n_fft, 1/sample_rate).to(DEVICE) # Move freqs to device\n",
    "            spec_sum_over_time = spec.sum(dim=-1)\n",
    "\n",
    "            valid_freq_indices = torch.where((freqs >= 50.0) & (freqs <= 500.0))[0]\n",
    "            if len(valid_freq_indices) > 0:\n",
    "                 max_mag_idx_in_valid = torch.argmax(spec_sum_over_time[valid_freq_indices])\n",
    "                 main_freq_idx = valid_freq_indices[max_mag_idx_in_valid]\n",
    "            else:\n",
    "                 main_freq_idx = torch.argmax(spec_sum_over_time)\n",
    "\n",
    "            dominant_freq = freqs[main_freq_idx].item()\n",
    "            return dominant_freq\n",
    "\n",
    "        except Exception as fallback_e:\n",
    "            print(f\"Spectrogram fallback also failed for {os.path.basename(audio_path)}: {fallback_e}\")\n",
    "            return None\n",
    "\n",
    "# --- Iterate and Extract Pitch ---\n",
    "print(\"Starting pitch extraction...\")\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Extracting pitch\"):\n",
    "    # Construct full audio path, handle potential missing values in 'path' column\n",
    "    relative_path = row.get('path') # Use .get for safety if 'path' column might be missing\n",
    "    if pd.isna(relative_path):\n",
    "        # print(f\"Warning: Missing audio path for row index {idx}. Skipping.\")\n",
    "        continue # Skip row if path is NaN or None\n",
    "\n",
    "    audio_file = os.path.join(AUDIO_ROOT, relative_path)\n",
    "\n",
    "    if os.path.exists(audio_file):\n",
    "        # extract_pitch handles internal errors and returns None on failure\n",
    "        pitch_value = extract_pitch(audio_file)\n",
    "        # Use .loc for potentially faster assignment, especially on large dataframes\n",
    "        df.loc[idx, 'pitch_mean'] = pitch_value\n",
    "    else:\n",
    "        print(f\"Warning: Audio file not found at {audio_file} for row index {idx}. Skipping.\")\n",
    "        # df.loc[idx, 'pitch_mean'] = None # Already initialized to None, but explicit is ok\n",
    "\n",
    "# --- Save Output ---\n",
    "print(f\"\\nSaving results to {OUTPUT_CSV}...\")\n",
    "try:\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(\"Pitch extraction complete.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving CSV file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99d38c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
